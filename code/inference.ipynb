{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# This python file for inferencing the EDANet model.\n",
    "\n",
    "@ Author: Md Mostafa Kamal Sarker\n",
    "@ email: m.kamal.sarker@gmail.com\n",
    "@ Date: 17.05.2020\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "## import pytorch library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torchnet.meter as meter\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "##  model\n",
    "from edanet import EDANet\n",
    "## other libraries\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data source path\n",
    "data_dir = 'E:/EDANet/test_data'\n",
    "target_names=  os.listdir(os.path.join(data_dir, 'val')) #\n",
    "# print (target_names)\n",
    "num_classes=len(target_names)\n",
    "\n",
    "## test data loader\n",
    "valdir = os.path.join(data_dir, 'val')\n",
    "normalize  = transforms.Normalize([0.5], [0.5]) # used gray image\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(330),\n",
    "        transforms.CenterCrop(320),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=8, shuffle=False,\n",
    "    num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.close('all')\n",
    "\n",
    "    plt.imshow(cm, interpolation='none', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout(pad=2)\n",
    "    plt.margins(0.1)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use cuda\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model checkpoint and model\n",
    "PATH = 'results/best_checkpoint.pth.tar'\n",
    "model = EDANet(num_classes=3).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "### define final validation for confusion matrix and other results\n",
    "def final_validate(val_loader, model, device, target_names,num_classes, criterion):\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    Pr = []\n",
    "    Tr = []\n",
    "    Flag = True\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss= criterion(output, target)            \n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            ## for calculating confusion matrix\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            predicted = predicted.cpu().numpy()\n",
    "            predicted=predicted.reshape((-1,1))\n",
    "            target = target.cpu().data.numpy()\n",
    "            # print(target.shape)\n",
    "            target = target.reshape((-1, 1))\n",
    "            if Flag==True:\n",
    "                Pr = predicted\n",
    "                Tr = target\n",
    "                Flag=False\n",
    "            else:\n",
    "                Pr=np.vstack((Pr,predicted))\n",
    "                Tr=np.vstack((Tr,target))\n",
    "    PlotTr(Tr, Pr, target_names,num_classes)\n",
    "\n",
    "\n",
    "def Plot(target_var, predicted, target_names,num_classes):\n",
    "    \"\"\" \n",
    "    Plots and results\n",
    "    \"\"\"\n",
    "    # Compute confusion matrix\n",
    "    cnf_matrix = confusion_matrix(target_var, predicted)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Plot normalized confusion matrix\n",
    "    class_names = [target_names[i] for i in range(num_classes)]\n",
    "    print(class_names)\n",
    "\n",
    "    ##Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names) #\n",
    "\n",
    " \n",
    "    plt.savefig('results/EDANet'+'Confusion_matrix_WN.png',dpi = (300))\n",
    " \n",
    "\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                            title='Normalized confusion matrix') #\n",
    "\n",
    "    # plt.show()\n",
    "    plt.savefig('results/EDANet'+'Confusion_matrix_Nor.png',dpi = (300))\n",
    "\n",
    "    ###\n",
    "    matrix = cnf_matrix.astype('float')\n",
    "    cm_norm = matrix / matrix.sum(axis=1)[:, np.newaxis]\n",
    "    print(matrix)\n",
    "    acc = np.array(cm_norm.diagonal())\n",
    "    class_acc = [matrix[i,i]/np.sum(matrix[i,:]) if np.sum(matrix[i,:]) else 0 for i in range(len(matrix))]\n",
    "    print('Sens COVID-19: {0:.3f}, Normal : {1:.3f},  Pneumonia: {2:.3f}'.format(class_acc[0],\n",
    "                                                                               class_acc[1],\n",
    "                                                                               class_acc[2]))\n",
    "    ppvs = [matrix[i,i]/np.sum(matrix[:,i]) if np.sum(matrix[:,i]) else 0 for i in range(len(matrix))]\n",
    "    print('PPV COVID-19: {0:.3f}, Normal:  {1:.3f},  Pneumonia: {2:.3f}'.format(ppvs[0],\n",
    "                                                                             ppvs[1],\n",
    "                                                                             ppvs[2]))\n",
    "\n",
    "    #### save results\n",
    "    clf_rep=classification_report(target_var,predicted, target_names=target_names)\n",
    "    cnf_matrix=confusion_matrix(target_var, predicted)\n",
    "    file_perf = open('results/EDANet'+'performances.txt', 'w')\n",
    "    file_perf.write(\"classification Report:\\n\" + str(clf_rep)\n",
    "                    + \"\\n\\nConfusion matrix:\\n\"\n",
    "                    + str(cnf_matrix)\n",
    "                    )\n",
    "    file_perf.close() \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_validate(val_loader, model, device, target_names,num_classes, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}